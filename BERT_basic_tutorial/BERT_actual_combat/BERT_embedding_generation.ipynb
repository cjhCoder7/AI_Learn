{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT 嵌入生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "安装Transformers库，这里使用的版本是3.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install Transformers==3.5.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT的顶层编码器（编码器12）获得嵌入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下载预训练的BERT模型，使用的是不区分大小写的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased')  # 下载并加载预训练模型\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')  # 下载并加载用于预训练模型的词元分析器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 输入预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'I love Paris'\n",
    "# 对句子进行分词\n",
    "tokens = tokenizer.tokenize(sentence)\n",
    "print(tokens)\n",
    "# 添加[CLS]和[SEP]\n",
    "tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
    "print(tokens)\n",
    "# 统一长度为7\n",
    "tokens = tokens + ['[PAD]'] + ['[PAD]']\n",
    "print(tokens)\n",
    "# 获取注意力掩码\n",
    "attention_mask = [1 if i != '[PAD]' else 0 for i in tokens]\n",
    "print(attention_mask)\n",
    "# 获取标记ID\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`unsqueeze()` 的目的是改变张量的形状，增加一个维度。下面两个都将变为 1 * 7 的二维矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将注意力掩码和标记ID转化为张量，方便后续计算\n",
    "token_ids = torch.tensor(token_ids).unsqueeze(0)\n",
    "attention_mask = 1 - torch.tensor(attention_mask).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 获取嵌入向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_rep, cls_head = model(token_ids, attention_mask = attention_mask)\n",
    "print(hidden_rep.shape)\n",
    "print(cls_head.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第1个值`hidden_rep`表示隐藏状态的特征，它包括从顶层编码器（编码器12）获得的所有标记的特征。第2个值`cls_head`表示`[CLS]`标记的特征\n",
    "- `hidden_rep[0][0]`给出了第1个标记[CLS]的特征。\n",
    "- `hidden_rep[0][1]`给出了第2个标记`I`的特征。\n",
    "- `hidden_rep[0][2]`给出了第3个标记`love`的特征。\n",
    "\n",
    "`cls_head`作为句子I love Paris的整句特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT的所有编码器层获得嵌入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下载预训练的BERT模型和词元分析器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states = True) # 允许我们从所有编码层获得嵌入\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 输入预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'I love Paris'\n",
    "tokens = tokenizer.tokenize(sentence)\n",
    "tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
    "tokens = tokens + ['[PAD]'] + ['[PAD]']\n",
    "\n",
    "attention_mask = [1 if i != '[PAD]' else 0 for i in tokens]\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "token_ids = torch.tensor(token_ids).unsqueeze(0)\n",
    "attention_mask = torch.tensor(attention_mask).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 获取嵌入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_hidden_state, pooler_output, hidden_states = model(token_ids, attention_mask = attention_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `last_hidden_state`包含从最后的编码器（编码器12）中获得的所有标记的特征。\n",
    "- `pooler_output`表示来自最后的编码器的[CLS]标记的特征，它被一个线性激活函数和tanh激活函数进一步处理。\n",
    "- `hidden_states`包含从所有编码器层获得的所有标记的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `last_hidden_state[0][0]`给出了第1个标记[CLS]的特征。\n",
    "- `last_hidden_state[0][1]`给出了第2个标记`I`的特征。\n",
    "- `last_hidden_state[0][2]`给出了第3个标记`love`的特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pooler_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pooler_output`作为句子I love Paris的整句特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hidden_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `hidden_states[0]`包含从输入嵌入层获得的所有标记的特征。\n",
    "- `hidden_states[1]`包含从第1个编码器层获得的所有标记的特征。\n",
    "- `hidden_states[2]`包含从第2个编码器层获得的所有标记的特征。\n",
    "- `hidden_states[12]`包含从最后一个编码器层获得的所有标记的特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hidden_states[0].shape)\n",
    "print(hidden_states[1].shape)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
